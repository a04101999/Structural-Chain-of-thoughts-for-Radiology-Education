{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install scikit-learn\n",
    "% pip install matplotlib\n",
    "% pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupiter notebook evaluates the performance of the baseline zero-shot and few-shot prompting on the synthesized error dataset, to compare the effectiveness of the SCot framework in improving multimodal reasoning across different LLM/LMM models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the path's with the correct paths to your results generated using each prompting method with the respective models. Wherever the path is mentioned `with open`, please replace with your path to the respective file.\n",
    "\n",
    "```python\n",
    "with open(\".\\llama3.211BV\\llama3.2_11B_zshot_predictions.json\") as file:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label_dict(label_dict):\n",
    "    # Define the mapping between class labels and the corresponding descriptions\n",
    "    label_mapping = {\n",
    "        'class_label_1': 'Missed abnormality due to missing fixation',\n",
    "        'class_label_2': 'Missed abnormality due to reduced fixation',\n",
    "        'class_label_3': 'Missed abnormality due to incomplete knowledge'\n",
    "    }\n",
    "\n",
    "    transformed_dict = {}\n",
    "\n",
    "    for key, value in label_dict.items():\n",
    "        transformed_dict[key] = {}\n",
    "\n",
    "        # Map each label to its new description based on `label_mapping`\n",
    "        for class_label, new_description in label_mapping.items():\n",
    "            transformed_dict[key][new_description] = value.get(class_label, 0)\n",
    "        \n",
    "        # Set \"No missing abnormality\" based on all class labels being 0\n",
    "        transformed_dict[key]['No missing abnormality'] = int(all(\n",
    "            value.get(class_label, 0) == 0 for class_label in label_mapping\n",
    "        ))\n",
    "\n",
    "    return transformed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, hamming_loss, roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.roc_auc_score.html#roc-auc-score\n",
    "\"\"\"\n",
    "\n",
    "def generate_metrics(predictions: list[dict], ground_truth: list[dict]):\n",
    "    # Predictions and ground truth data\n",
    "\n",
    "    # Extract labels from ground truth and predictions\n",
    "    # ['Missed abnormality due to missing fixation', 'Missed abnormality due to reduced fixation', 'Missed abnormality due to incomplete knowledge', 'No missing abnormality']\n",
    "    labels = list(predictions[0].keys())\n",
    "\n",
    "    y_true = np.array([[gt[label] for label in labels] for gt in ground_truth])\n",
    "    y_pred = np.array([[pred[label] for label in labels] for pred in predictions])\n",
    "\n",
    "    # Calculate multilabel classification metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=labels, digits=4))\n",
    "\n",
    "    print(\"\\nAccuracy Score:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_true, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_true, y_pred, average='macro', multi_class='ovr'))\n",
    "    print()\n",
    "\n",
    "    # Calculate ROC AUC and Precision-Recall AUC for each label\n",
    "    for i, label in enumerate(labels):\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            avg_precision = average_precision_score(y_true[:, i], y_pred[:, i])\n",
    "            accuracy = accuracy_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "            print(f\"Accuracy for {label}: {accuracy}\")\n",
    "            print(f\"ROC AUC for {label}: {roc_auc}\")\n",
    "            print(\"Hamming loss\", hamming_loss(y_true[:, i], y_pred[:, i]))\n",
    "            print(\"--------------------------------------------------\")\n",
    "        \n",
    "        except ValueError:\n",
    "            print(f\"\\nROC AUC and Average Precision for {label} could not be calculated due to lack of positive samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_inference_time(predictions: list[dict]):\n",
    "    \"\"\"\n",
    "    Calculate the average inference time from the predictions.\n",
    "    Assumes that each prediction dictionary contains an 'inference_time' key.\n",
    "    \"\"\"\n",
    "    total_time = 0\n",
    "    count = 0\n",
    "\n",
    "    for pred in predictions:\n",
    "        if 'inference_time' in pred:\n",
    "            total_time += pred['inference_time']\n",
    "            count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        return 0\n",
    "\n",
    "    return total_time / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate(results_file_path: str, ground_truth_metadata: dict):\n",
    "    with open (results_file_path) as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    predictions = []\n",
    "    transformed_gt = transform_label_dict(ground_truth_metadata)\n",
    "    ground_truth = []\n",
    "\n",
    "    for dicom_id, pred in results.items():\n",
    "        predictions.append(pred)\n",
    "        ground_truth.append(transformed_gt[dicom_id])\n",
    "\n",
    "    assert len(predictions) == len(ground_truth)\n",
    "\n",
    "    print(\"Average Inference Time:\", round(get_average_inference_time(predictions), 3), \"seconds\")\n",
    "\n",
    "    generate_metrics(predictions, ground_truth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Replace with the actual file paths\n",
    "\n",
    "with open(\"orig_xy_fixation_transcript_metadata.json\", 'r') as file:\n",
    "    orig_xy_ground_truth_metadata = json.load(file)\n",
    "\n",
    "with open(\"orig_xy_fixation_transcript_data.json\", 'r') as file:\n",
    "    orig_xy_fixation_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLAMA-3.2-11B-Vision-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.5601    0.8310    0.6692       432\n",
      "    Missed abnormality due to reduced fixation     0.6353    0.2500    0.3588       432\n",
      "Missed abnormality due to incomplete knowledge     0.3889    0.0870    0.1421       161\n",
      "                        No missing abnormality     0.6224    0.8472    0.7176       216\n",
      "\n",
      "                                     micro avg     0.5819    0.5351    0.5575      1241\n",
      "                                     macro avg     0.5517    0.5038    0.4719      1241\n",
      "                                  weighted avg     0.5749    0.5351    0.5012      1241\n",
      "                                   samples avg     0.5615    0.5176    0.5249      1241\n",
      "\n",
      "\n",
      "Accuracy Score: 0.40780487804878046\n",
      "Hamming Loss: 0.2570731707317073\n",
      "ROC AUC Score: 0.6590533364237444\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6536585365853659\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.6777352289051277\n",
      "Hamming loss 0.3463414634146341\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.6234146341463415\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.5727234401349073\n",
      "Hamming loss 0.37658536585365854\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.8351219512195122\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.5307467793880837\n",
      "Hamming loss 0.1648780487804878\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.8595121951219512\n",
      "ROC AUC for No missing abnormality: 0.855007897266859\n",
      "Hamming loss 0.1404878048780488\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brandon Chung\\Desktop\\HULA_egd_cxr\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\llama3.211BV\\llama3.2_11B_zshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025 1025\n",
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.5529    0.9074    0.6871       432\n",
      "    Missed abnormality due to reduced fixation     0.6449    0.4120    0.5028       432\n",
      "Missed abnormality due to incomplete knowledge     0.2879    0.1180    0.1674       161\n",
      "                        No missing abnormality     0.8964    0.8009    0.8460       216\n",
      "\n",
      "                                     micro avg     0.6125    0.6140    0.6133      1241\n",
      "                                     macro avg     0.5955    0.5596    0.5508      1241\n",
      "                                  weighted avg     0.6103    0.6140    0.5832      1241\n",
      "                                   samples avg     0.5844    0.5863    0.5686      1241\n",
      "\n",
      "\n",
      "Accuracy Score: 0.43317073170731707\n",
      "Hamming Loss: 0.234390243902439\n",
      "ROC AUC Score: 0.6824289249729698\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6517073170731708\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.686418712135407\n",
      "Hamming loss 0.34829268292682924\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.6565853658536586\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.6233878271188558\n",
      "Hamming loss 0.3434146341463415\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.8156097560975609\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.5318071371060501\n",
      "Hamming loss 0.18439024390243902\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.9385365853658536\n",
      "ROC AUC for No missing abnormality: 0.8881020235315663\n",
      "Hamming loss 0.06146341463414634\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brandon Chung\\Desktop\\HULA_egd_cxr\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\llama3.211BV\\llama3.2_11B_fshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.5565    0.7343    0.6332       429\n",
      "    Missed abnormality due to reduced fixation     0.7059    0.0837    0.1497       430\n",
      "Missed abnormality due to incomplete knowledge     0.1207    0.0435    0.0639       161\n",
      "                        No missing abnormality     0.3408    0.9167    0.4969       216\n",
      "\n",
      "                                     micro avg     0.4427    0.4498    0.4462      1236\n",
      "                                     macro avg     0.4310    0.4445    0.3359      1236\n",
      "                                  weighted avg     0.5140    0.4498    0.3670      1236\n",
      "                                   samples avg     0.4454    0.4413    0.4318      1236\n",
      "\n",
      "\n",
      "Accuracy Score: 0.30332681017612523\n",
      "Hamming Loss: 0.337573385518591\n",
      "ROC AUC Score: 0.5993878374572252\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6428571428571429\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.655497116711282\n",
      "Hamming loss 0.35714285714285715\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.5998043052837574\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.5291915461973602\n",
      "Hamming loss 0.40019569471624267\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.799412915851272\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.49212240569610666\n",
      "Hamming loss 0.20058708414872797\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.6076320939334638\n",
      "ROC AUC for No missing abnormality: 0.7207402812241521\n",
      "Hamming loss 0.3923679060665362\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\mistral\\mistral_fshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.6483    0.3550    0.4588       431\n",
      "    Missed abnormality due to reduced fixation     0.6172    0.2993    0.4031       431\n",
      "Missed abnormality due to incomplete knowledge     0.2952    0.1925    0.2331       161\n",
      "                        No missing abnormality     0.5335    0.9213    0.6757       216\n",
      "\n",
      "                                     micro avg     0.5547    0.4132    0.4736      1239\n",
      "                                     macro avg     0.5236    0.4420    0.4427      1239\n",
      "                                  weighted avg     0.5716    0.4132    0.4479      1239\n",
      "                                   samples avg     0.5000    0.4175    0.4450      1239\n",
      "\n",
      "\n",
      "Accuracy Score: 0.3349609375\n",
      "Hamming Loss: 0.27783203125\n",
      "ROC AUC Score: 0.6490209714516919\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6474609375\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.607511062942371\n",
      "Hamming loss 0.3525390625\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.626953125\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.5821983465253949\n",
      "Hamming loss 0.373046875\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.80078125\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.5533995955175863\n",
      "Hamming loss 0.19921875\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.8134765625\n",
      "ROC AUC for No missing abnormality: 0.8529748808214155\n",
      "Hamming loss 0.1865234375\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brandon Chung\\Desktop\\HULA_egd_cxr\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\mistral\\mistral_zshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o-Mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.5483    0.9583    0.6976       432\n",
      "    Missed abnormality due to reduced fixation     0.6842    0.5417    0.6047       432\n",
      "Missed abnormality due to incomplete knowledge     0.1852    0.7640    0.2982       161\n",
      "                        No missing abnormality     0.9863    1.0000    0.9931       216\n",
      "\n",
      "                                     micro avg     0.4985    0.7953    0.6129      1241\n",
      "                                     macro avg     0.6010    0.8160    0.6484      1241\n",
      "                                  weighted avg     0.6248    0.7953    0.6648      1241\n",
      "                                   samples avg     0.5351    0.7727    0.6125      1241\n",
      "\n",
      "\n",
      "Accuracy Score: 0.2546341463414634\n",
      "Hamming Loss: 0.3041463414634146\n",
      "ROC AUC Score: 0.7346178147899046\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6497560975609756\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.6916455874086567\n",
      "Hamming loss 0.35024390243902437\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.7014634146341463\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.6797709387296232\n",
      "Hamming loss 0.29853658536585365\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.4351219512195122\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.5689088739360478\n",
      "Hamming loss 0.5648780487804878\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.9970731707317073\n",
      "ROC AUC for No missing abnormality: 0.9981458590852904\n",
      "Hamming loss 0.002926829268292683\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\gpt4o\\gpt4o_mini_zshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "    Missed abnormality due to missing fixation     0.5519    0.9477    0.6976       421\n",
      "    Missed abnormality due to reduced fixation     0.6901    0.7458    0.7169       421\n",
      "Missed abnormality due to incomplete knowledge     0.1860    0.1491    0.1655       161\n",
      "                        No missing abnormality     0.8120    1.0000    0.8963       216\n",
      "\n",
      "                                     micro avg     0.6058    0.7818    0.6827      1219\n",
      "                                     macro avg     0.5600    0.7107    0.6191      1219\n",
      "                                  weighted avg     0.5974    0.7818    0.6692      1219\n",
      "                                   samples avg     0.6157    0.7406    0.6555      1219\n",
      "\n",
      "\n",
      "Accuracy Score: 0.4832347140039448\n",
      "Hamming Loss: 0.21844181459566075\n",
      "ROC AUC Score: 0.7340943778462388\n",
      "\n",
      "Accuracy for Missed abnormality due to missing fixation: 0.6587771203155819\n",
      "ROC AUC for Missed abnormality due to missing fixation: 0.700684550155616\n",
      "Hamming loss 0.34122287968441817\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to reduced fixation: 0.7554240631163708\n",
      "ROC AUC for Missed abnormality due to reduced fixation: 0.7540346000248344\n",
      "Hamming loss 0.2445759368836292\n",
      "--------------------------------------------------\n",
      "Accuracy for Missed abnormality due to incomplete knowledge: 0.7613412228796844\n",
      "ROC AUC for Missed abnormality due to incomplete knowledge: 0.5129866820065098\n",
      "Hamming loss 0.23865877712031558\n",
      "--------------------------------------------------\n",
      "Accuracy for No missing abnormality: 0.9506903353057199\n",
      "ROC AUC for No missing abnormality: 0.968671679197995\n",
      "Hamming loss 0.04930966469428008\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluate(\".\\gpt4o\\gpt4o_mini_fshot_predictions.json\", orig_xy_ground_truth_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
